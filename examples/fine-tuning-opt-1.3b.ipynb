{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d5157c230947ab84ef07de306f306d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 15000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 750\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_training_samples = 15000\n",
    "num_test_samples = 750\n",
    "num_validation_samples = 1000\n",
    "training_samples = squad['train'].select([i for i in range(num_training_samples)])\n",
    "test_samples = squad['train'].select([i for i in range(num_training_samples, num_training_samples+num_test_samples)])\n",
    "validation_samples = squad['validation'].select([i for i in range(num_validation_samples)])\n",
    "print(training_samples)\n",
    "print(test_samples)\n",
    "print(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"facebook/opt-1.3b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set the chat template clearly:\n",
    "tokenizer.chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'system' %}<|system|>\\n{{ message['content'] }}\\n\"\n",
    "    \"{% elif message['role'] == 'user' %}<|start_header_id|>user<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% elif message['role'] == 'assistant' %}<|start_header_id|>assistant<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_squad_sample_to_llama_conversation(sample):\n",
    "    question = sample['question']\n",
    "    context = sample['context']\n",
    "\n",
    "    answers = sample['answers']['text']\n",
    "    if len(answers) == 0:\n",
    "        answer = \"The context does not provide an answer...\"\n",
    "    else:\n",
    "        answer = answers[0]\n",
    "\n",
    "    instruction_prompt_template = '''\n",
    "    You are a helpful assistant tasked with extracting exact passages from the context that answer the user's questions. \n",
    "    Output exact passages word for word from the context. If the answer isn't found, reply \"The context does not provide an answer...\".\n",
    "\n",
    "    Context: {context}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction_prompt_template.format(context=context)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    # Tokenize the entire conversation explicitly as text\n",
    "    conversation_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    # Tokenize the conversation text\n",
    "    tokenized_output = tokenizer(\n",
    "        conversation_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    labels = tokenized_output['input_ids'].clone()\n",
    "\n",
    "    # Prepare prompt text explicitly for masking\n",
    "    prompt_messages = messages[:-1]  # exclude assistant's response\n",
    "    prompt_text = tokenizer.apply_chat_template(prompt_messages, tokenize=False)\n",
    "    prompt_tokens = tokenizer(prompt_text, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    # Explicitly mask the prompt tokens in the labels\n",
    "    labels[:, :len(prompt_tokens)] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": tokenized_output[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": tokenized_output[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": labels.squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = training_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=training_samples.column_names\n",
    ")\n",
    "\n",
    "tokenized_validation_dataset = validation_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation, \n",
    "    remove_columns=validation_samples.column_names\n",
    "    )\n",
    "\n",
    "tokenized_test_dataset = test_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=test_samples.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Safetensors PR exists\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# to help save on gpu space and run this a bit faster we'll load the model in 4bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "# rank defines the rank of the adapter matrix,\n",
    "# the higher the rank, the more complex the task it's trying to learn\n",
    "rank = 128\n",
    "\n",
    "# the alpha is a scaling factor hyper parameter, basically controls how much our\n",
    "# adapter will influence the models output, the higher this value\n",
    "# the more our adapter will overpower the original model weights.\n",
    "# there is a lot of advice out there for what the alpha value should be\n",
    "# keeping the alpha at around 2x of what the rank is works for this notebook\n",
    "alpha = rank*2\n",
    "peft_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=alpha,\n",
    "    lora_dropout=0.05, # dropout for the lora layers while training, to avoid overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # the target modules defines what types of layers to add lora adapters too, so in the network\n",
    "    # any model that have a name in this list will have a lora adapter added to it,\n",
    "    target_modules=['k_proj', 'q_proj', 'v_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715829793fe040349a435ae455579b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62602831c76e4da28fdf8aecf4d82d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99719626cd24fd0b282bc8e512e931d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56b4885fcb64d3086ccc9b5ae8740b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_checkpoint_path = \"./results/opt-1.3b\"\n",
    "\n",
    "# an important note is that the loss function isn't defined here,\n",
    "# it's instead stored as a model parameter for models in hf,\n",
    "# in the case of llama it is cross entropy loss\n",
    "\n",
    "# first define some training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=model_checkpoint_path,\n",
    "    optim='adamw_torch', #specify what optimizer we wwant to use, in this case a 8bit version of adamw with pagination.\n",
    "    per_device_train_batch_size=8, # define the number of samples per training batch\n",
    "    gradient_accumulation_steps=4, # define how many steps to accumulate gradients,\n",
    "    log_level='debug',\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy='steps', # we'll save a checkpoint every epoch\n",
    "    logging_steps=8,\n",
    "    eval_steps=8,\n",
    "    save_steps=8,\n",
    "    learning_rate=1e-5, # for llm training we want a fairly high learning rate, 1e-4 is a good starting point but it's worth it to play around with this value\n",
    "    fp16=True,\n",
    "    num_train_epochs=4,\n",
    "    max_steps=120,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end = True,\n",
    "    overwrite_output_dir = True,\n",
    "    lr_scheduler_type='linear',# and set our learning rate decay\n",
    ")\n",
    "\n",
    "# now that we have our arguments, we'll use that to create our trainer,\n",
    "# passing in the model, dataset, peft config, tokenizer, ect\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37,748,736 || all params: 1,353,506,816 || trainable%: 2.7890\n"
     ]
    }
   ],
   "source": [
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 15,000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 120\n",
      "  Number of trainable parameters = 37,748,736\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 27:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.945500</td>\n",
       "      <td>2.772971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.757200</td>\n",
       "      <td>2.497755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.496200</td>\n",
       "      <td>2.253353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.307500</td>\n",
       "      <td>2.046264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.111100</td>\n",
       "      <td>1.857086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.976900</td>\n",
       "      <td>1.680419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.838900</td>\n",
       "      <td>1.567849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.730900</td>\n",
       "      <td>1.489866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.650200</td>\n",
       "      <td>1.447850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.575900</td>\n",
       "      <td>1.421904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.639100</td>\n",
       "      <td>1.405539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.580100</td>\n",
       "      <td>1.396251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.568600</td>\n",
       "      <td>1.390789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.545300</td>\n",
       "      <td>1.388027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.563700</td>\n",
       "      <td>1.387080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-8\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-8/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-16\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-16/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-16/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-24\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-24/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-32\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-32/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-32/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-40\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-40/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-48\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-48/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-48/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-56\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-56/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-64\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-64/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-64/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-72\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-72/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-80\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-80/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-88\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-88/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-96\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-96/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-96/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-104\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-104/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-104/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-112\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-112/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-112/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/opt-1.3b/checkpoint-120\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/opt-1.3b/checkpoint-120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/opt-1.3b/checkpoint-120/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/opt-1.3b/checkpoint-120 (score: 1.3870798349380493).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=1.952475078900655, metrics={'train_runtime': 1653.6372, 'train_samples_per_second': 2.322, 'train_steps_per_second': 0.073, 'total_flos': 2.94051177824256e+16, 'train_loss': 1.952475078900655})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/opt-1.3b\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./models/opt-1.3b/tokenizer_config.json\n",
      "Special tokens file saved in ./models/opt-1.3b/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./models/opt-1.3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3870798349380493, 'eval_runtime': 59.3378, 'eval_samples_per_second': 16.853, 'eval_steps_per_second': 2.107}\n"
     ]
    }
   ],
   "source": [
    "initial_eval_values = trainer.evaluate()\n",
    "print(initial_eval_values)\n",
    "initial_eval_loss = initial_eval_values['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9461, 2.7409, 2.4408, 2.2616, 2.0685, 1.9454, 1.8129, 1.703, 1.6261, 1.5538, 1.6202, 1.5628, 1.5523, 1.5303, 1.5484]\n",
      "[2.7664449214935303, 2.445246696472168, 2.1604299545288086, 1.9537863731384277, 1.7729519605636597, 1.6280579566955566, 1.5226621627807617, 1.4595332145690918, 1.4229938983917236, 1.4006072282791138, 1.389123558998108, 1.3825429677963257, 1.3781330585479736, 1.3762766122817993, 1.3756911754608154, 1.3756911754608154]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss_history = []\n",
    "eval_loss_history = []\n",
    "for step in trainer.state.log_history:\n",
    "  if 'loss' in step:\n",
    "    training_loss_history.append(step['loss'])\n",
    "  elif \"eval_loss\" in step:\n",
    "    eval_loss_history.append(step['eval_loss'])\n",
    "\n",
    "print(training_loss_history)\n",
    "print(eval_loss_history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_steps = [i*16 for i in range(1, len(training_loss_history)+1)]\n",
    "eval_time_steps = [i*16 for i in range(1, len(eval_loss_history)+1)]\n",
    "plt.plot(time_steps, training_loss_history, label=\"train loss\")\n",
    "plt.plot(eval_time_steps, eval_loss_history, label=\"eval loss\")\n",
    "plt.title(\"Train and Eval Loss During Training\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./models/opt-1.3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/pytorch_model.bin\n",
      "Instantiating OPTForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "Safetensors PR exists\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-1.3b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/vocab.json\n",
      "loading file merges.txt from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/pytorch_model.bin\n",
      "Instantiating OPTForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Attempting to create safetensors variant\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-1.3b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "Safetensors PR exists\n",
      "loading configuration file generation_config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/vocab.json\n",
      "loading file merges.txt from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--facebook--opt-1.3b/snapshots/3f5c25d0bc631cb57ac65913f76e22c2dfb61d62/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-1.3b\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 8192,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 2048\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did Beyonce start becoming popular?\n",
      "She's been popular since she was a kid. She's just now getting the recognition she deserves.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model_name = \"facebook/opt-1.3b\"\n",
    "trained_adapter_dir = modelpath  # your checkpoint folder clearly stated here\n",
    "\n",
    "# Load base tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Clearly load base model explicitly\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Explicitly load your trained LoRA adapters clearly\n",
    "model = PeftModel.from_pretrained(base_model, trained_adapter_dir)\n",
    "\n",
    "# Set tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Use model explicitly for inference clearly\n",
    "prompt = \"When did Beyonce start becoming popular?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_length=256)\n",
    "\n",
    "response = tokenizer.decode(output.squeeze(), skip_special_tokens=True)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
