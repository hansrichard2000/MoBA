{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92461d15d1b143aabec064e94be2cc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 15000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 750\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_training_samples = 15000\n",
    "num_test_samples = 750\n",
    "num_validation_samples = 1000\n",
    "training_samples = squad['train'].select([i for i in range(num_training_samples)])\n",
    "test_samples = squad['train'].select([i for i in range(num_training_samples, num_training_samples+num_test_samples)])\n",
    "validation_samples = squad['validation'].select([i for i in range(num_validation_samples)])\n",
    "print(training_samples)\n",
    "print(test_samples)\n",
    "print(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set the chat template clearly:\n",
    "tokenizer.chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'system' %}<|system|>\\n{{ message['content'] }}\\n\"\n",
    "    \"{% elif message['role'] == 'user' %}<|start_header_id|>user<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% elif message['role'] == 'assistant' %}<|start_header_id|>assistant<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_squad_sample_to_llama_conversation(sample):\n",
    "    question = sample['question']\n",
    "    context = sample['context']\n",
    "\n",
    "    answers = sample['answers']['text']\n",
    "    if len(answers) == 0:\n",
    "        answer = \"The context does not provide an answer...\"\n",
    "    else:\n",
    "        answer = answers[0]\n",
    "\n",
    "    instruction_prompt_template = '''\n",
    "You are a helpful assistant tasked with extracting exact passages from the context that answer the user's questions. \n",
    "Output exact passages word for word from the context. If the answer isn't found, reply \"The context does not provide an answer...\".\n",
    "\n",
    "Context: {context}\n",
    "'''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction_prompt_template.format(context=context)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    # Tokenize the entire conversation explicitly as text\n",
    "    conversation_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    # Tokenize the conversation text\n",
    "    tokenized_output = tokenizer(\n",
    "        conversation_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    labels = tokenized_output['input_ids'].clone()\n",
    "\n",
    "    # Prepare prompt text explicitly for masking\n",
    "    prompt_messages = messages[:-1]  # exclude assistant's response\n",
    "    prompt_text = tokenizer.apply_chat_template(prompt_messages, tokenize=False)\n",
    "    prompt_tokens = tokenizer(prompt_text, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    # Explicitly mask the prompt tokens in the labels\n",
    "    labels[:, :len(prompt_tokens)] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": tokenized_output[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": tokenized_output[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": labels.squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = training_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=training_samples.column_names\n",
    ")\n",
    "\n",
    "tokenized_validation_dataset = validation_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation, \n",
    "    remove_columns=validation_samples.column_names\n",
    "    )\n",
    "\n",
    "tokenized_test_dataset = test_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=test_samples.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52563b514d24cffb09a2bf49e06df6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# to help save on gpu space and run this a bit faster we'll load the model in 4bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "# rank defines the rank of the adapter matrix,\n",
    "# the higher the rank, the more complex the task it's trying to learn\n",
    "rank = 128\n",
    "\n",
    "# the alpha is a scaling factor hyper parameter, basically controls how much our\n",
    "# adapter will influence the models output, the higher this value\n",
    "# the more our adapter will overpower the original model weights.\n",
    "# there is a lot of advice out there for what the alpha value should be\n",
    "# keeping the alpha at around 2x of what the rank is works for this notebook\n",
    "alpha = rank*2\n",
    "peft_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=alpha,\n",
    "    lora_dropout=0.05, # dropout for the lora layers while training, to avoid overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # the target modules defines what types of layers to add lora adapters too, so in the network\n",
    "    # any model that have a name in this list will have a lora adapter added to it,\n",
    "    target_modules=['k_proj', 'q_proj', 'v_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "PyTorch: setting up devices\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bbc3fb163b490893212afdaaf97c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320573dbc26c436f98e27de323c3a260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5b0d2e0b56499ab7d0e1e64aa3eccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4b47ebe6a14d9fbff9a852c6e29165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc53783606b645f294942d4f951e3ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_checkpoint_path = \"./results/mistral\"\n",
    "\n",
    "# an important note is that the loss function isn't defined here,\n",
    "# it's instead stored as a model parameter for models in hf,\n",
    "# in the case of llama it is cross entropy loss\n",
    "\n",
    "# first define some training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=model_checkpoint_path,\n",
    "    optim='adafactor', #specify what optimizer we wwant to use, in this case a 8bit version of adamw with pagination.\n",
    "    per_device_train_batch_size=8, # define the number of samples per training batch\n",
    "    gradient_accumulation_steps=4, # define how many steps to accumulate gradients,\n",
    "    log_level='debug',\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy='steps', # we'll save a checkpoint every epoch\n",
    "    logging_steps=8,\n",
    "    eval_steps=8,\n",
    "    save_steps=8,\n",
    "    learning_rate=1e-5, # for llm training we want a fairly high learning rate, 1e-4 is a good starting point but it's worth it to play around with this value\n",
    "    fp16=True,\n",
    "    num_train_epochs=4,\n",
    "    max_steps=120,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end = True,\n",
    "    overwrite_output_dir = True,\n",
    "    lr_scheduler_type='linear',# and set our learning rate decay\n",
    ")\n",
    "\n",
    "# now that we have our arguments, we'll use that to create our trainer,\n",
    "# passing in the model, dataset, peft config, tokenizer, ect\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 335,544,320 || all params: 7,583,567,872 || trainable%: 4.4246\n"
     ]
    }
   ],
   "source": [
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 10:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.081723690032959, 'eval_model_preparation_time': 0.0004, 'eval_runtime': 219.8321, 'eval_samples_per_second': 4.549, 'eval_steps_per_second': 0.569}\n"
     ]
    }
   ],
   "source": [
    "initial_eval_values = trainer.evaluate()\n",
    "print(initial_eval_values)\n",
    "initial_eval_loss = initial_eval_values['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 15,000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 120\n",
      "  Number of trainable parameters = 335,544,320\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 1:41:20, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.805400</td>\n",
       "      <td>1.396859</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.161800</td>\n",
       "      <td>0.986772</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>0.966280</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.007500</td>\n",
       "      <td>0.958962</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.977200</td>\n",
       "      <td>0.957675</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.977100</td>\n",
       "      <td>0.952789</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.951500</td>\n",
       "      <td>0.949934</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.948931</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.914800</td>\n",
       "      <td>0.953988</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.948556</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.966300</td>\n",
       "      <td>0.948732</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>0.949939</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.947593</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.891900</td>\n",
       "      <td>0.948606</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.919300</td>\n",
       "      <td>0.948532</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-8\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-8/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-16\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-16/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-16/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-24\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-24/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-32\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-32/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-32/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-40\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-40/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-48\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-48/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-48/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-56\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-56/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-64\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-64/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-64/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-72\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-72/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-80\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-80/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-88\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-88/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-96\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-96/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-96/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-104\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-104/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-104/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-112\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-112/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-112/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/mistral/checkpoint-120\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/mistral/checkpoint-120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/mistral/checkpoint-120/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/mistral/checkpoint-104 (score: 0.9475934505462646).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=1.0129740834236145, metrics={'train_runtime': 6103.6901, 'train_samples_per_second': 0.629, 'train_steps_per_second': 0.02, 'total_flos': 1.7575221997338624e+17, 'train_loss': 1.0129740834236145})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/mistral\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--mistralai--Mistral-7B-v0.3/snapshots/d8cadc02ac76bd617a919d50b092e59d2d110aff/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./models/mistral/tokenizer_config.json\n",
      "Special tokens file saved in ./models/mistral/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./models/mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: context, text, id, question, title, answer, answers. If context, text, id, question, title, answer, answers are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='94' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [94/94 51:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.13447105884552, 'eval_model_preparation_time': 0.0031, 'eval_runtime': 3123.112, 'eval_samples_per_second': 0.24, 'eval_steps_per_second': 0.03}\n"
     ]
    }
   ],
   "source": [
    "# initial_eval_values = trainer.evaluate()\n",
    "# print(initial_eval_values)\n",
    "# initial_eval_loss = initial_eval_values['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8054, 1.1618, 0.9895, 1.0075, 0.9772, 0.9771, 0.9515, 0.931, 0.9148, 0.886, 0.9663, 0.8957, 0.9196, 0.8919, 0.9193]\n",
      "[2.081723690032959, 1.3968594074249268, 0.986771821975708, 0.9662796258926392, 0.9589617848396301, 0.9576748013496399, 0.9527888298034668, 0.949933648109436, 0.948930561542511, 0.9539878964424133, 0.9485557675361633, 0.9487319588661194, 0.9499394297599792, 0.9475934505462646, 0.9486063122749329, 0.9485318660736084]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss_history = []\n",
    "eval_loss_history = [initial_eval_loss]\n",
    "for step in trainer.state.log_history:\n",
    "  if 'loss' in step:\n",
    "    training_loss_history.append(step['loss'])\n",
    "  elif \"eval_loss\" in step:\n",
    "    eval_loss_history.append(step['eval_loss'])\n",
    "\n",
    "print(training_loss_history)\n",
    "print(eval_loss_history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "time_steps = [i*16 for i in range(1, len(training_loss_history)+1)]\n",
    "plt.plot(time_steps, training_loss_history, label=\"train loss\")\n",
    "plt.plot([0]+time_steps, eval_loss_history, label=\"eval loss\")\n",
    "plt.title(\"Train and Eval Loss During Training\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./models/mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f7ae28b9444d1ca4190169af710885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3405b9870964c0c8a4fe0116718fcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did Beyonce start becoming popular?\n",
      "\n",
      "- Beyoncé Giselle Knowles was born on September 4, 1981, in Houston, Texas. She was raised in a family of musicians. Her father, Mathew Knowles, was a Xerox sales manager and also managed Destiny’s Child. Her mother, Tina Knowles, was a hairdresser and salon owner.\n",
      "\n",
      "## What is Beyonce’s net worth?\n",
      "\n",
      "Beyoncé’s net worth is estimated to be $420 million, according to Forbes. She’s also one of the world’s highest-paid celebrities.\n",
      "\n",
      "## How much is Beyonce worth 2020?\n",
      "\n",
      "Beyoncé’s net worth is estimated to be $420 million, according to Forbes. She’s also one of the world’s highest-paid celebrities.\n",
      "\n",
      "## How much is Jay Z worth?\n",
      "\n",
      "Jay-Z’s net worth is estimated to be roughly $1 billion dollars, making him one of the richest rappers of all time and the first billionaire in hip-hop.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model_name = \"mistralai/Mistral-7B-v0.3\"\n",
    "trained_adapter_dir = modelpath  # your checkpoint folder clearly stated here\n",
    "\n",
    "# Load base tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Clearly load base model explicitly\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Explicitly load your trained LoRA adapters clearly\n",
    "model = PeftModel.from_pretrained(base_model, trained_adapter_dir)\n",
    "\n",
    "# Set tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "\n",
    "# Use model explicitly for inference clearly\n",
    "prompt = \"When did Beyonce start becoming popular?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_length=256)\n",
    "\n",
    "response = tokenizer.decode(output.squeeze(), skip_special_tokens=True)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
