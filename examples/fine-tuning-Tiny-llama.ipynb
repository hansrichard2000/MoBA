{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992c356d9084487baf1ff8b67cfc7d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_scheduler, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "squad = load_dataset(\"squad_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 15000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 750\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "num_training_samples = 15000\n",
    "num_test_samples = 750\n",
    "num_validation_samples = 1000\n",
    "training_samples = squad['train'].select([i for i in range(num_training_samples)])\n",
    "test_samples = squad['train'].select([i for i in range(num_training_samples, num_training_samples+num_test_samples)])\n",
    "validation_samples = squad['validation'].select([i for i in range(num_validation_samples)])\n",
    "print(training_samples)\n",
    "print(test_samples)\n",
    "print(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be85543aeaaa14008c9063',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
       " 'question': 'When did Beyonce start becoming popular?',\n",
       " 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly set the chat template clearly:\n",
    "tokenizer.chat_template = (\n",
    "    \"{% for message in messages %}\"\n",
    "    \"{% if message['role'] == 'system' %}<|system|>\\n{{ message['content'] }}\\n\"\n",
    "    \"{% elif message['role'] == 'user' %}<|start_header_id|>user<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% elif message['role'] == 'assistant' %}<|start_header_id|>assistant<|end_header_id|>{{ message['content'] }}<|eot_id|>\"\n",
    "    \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_squad_sample_to_llama_conversation(sample):\n",
    "    question = sample['question']\n",
    "    context = sample['context']\n",
    "\n",
    "    answers = sample['answers']['text']\n",
    "    if len(answers) == 0:\n",
    "        answer = \"The context does not provide an answer...\"\n",
    "    else:\n",
    "        answer = answers[0]\n",
    "\n",
    "    instruction_prompt_template = '''\n",
    "    You are a helpful assistant tasked with extracting exact passages from the context that answer the user's questions. \n",
    "    Output exact passages word for word from the context. If the answer isn't found, reply \"The context does not provide an answer...\".\n",
    "\n",
    "    Context: {context}\n",
    "    '''\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruction_prompt_template.format(context=context)},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    # Tokenize the entire conversation explicitly as text\n",
    "    conversation_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    # Tokenize the conversation text\n",
    "    tokenized_output = tokenizer(\n",
    "        conversation_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    labels = tokenized_output['input_ids'].clone()\n",
    "\n",
    "    # Prepare prompt text explicitly for masking\n",
    "    prompt_messages = messages[:-1]  # exclude assistant's response\n",
    "    prompt_text = tokenizer.apply_chat_template(prompt_messages, tokenize=False)\n",
    "    prompt_tokens = tokenizer(prompt_text, add_special_tokens=False)['input_ids']\n",
    "\n",
    "    # Explicitly mask the prompt tokens in the labels\n",
    "    labels[:, :len(prompt_tokens)] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": tokenized_output[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": tokenized_output[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": labels.squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b059fe4066d49ed92d036cf62b15efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e4cfca89d74fe6b1ad972c26b7354e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca73d5b4cc14d25ab6ff5869236ca2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = training_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=training_samples.column_names\n",
    ")\n",
    "\n",
    "tokenized_validation_dataset = validation_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation, \n",
    "    remove_columns=validation_samples.column_names\n",
    "    )\n",
    "\n",
    "tokenized_test_dataset = test_samples.map(\n",
    "    convert_squad_sample_to_llama_conversation,\n",
    "    remove_columns=test_samples.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# to help save on gpu space and run this a bit faster we'll load the model in 4bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "# rank defines the rank of the adapter matrix,\n",
    "# the higher the rank, the more complex the task it's trying to learn\n",
    "rank = 128\n",
    "\n",
    "# the alpha is a scaling factor hyper parameter, basically controls how much our\n",
    "# adapter will influence the models output, the higher this value\n",
    "# the more our adapter will overpower the original model weights.\n",
    "# there is a lot of advice out there for what the alpha value should be\n",
    "# keeping the alpha at around 2x of what the rank is works for this notebook\n",
    "alpha = rank*2\n",
    "peft_config = LoraConfig(\n",
    "    r=rank,\n",
    "    lora_alpha=alpha,\n",
    "    lora_dropout=0.05, # dropout for the lora layers while training, to avoid overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    # the target modules defines what types of layers to add lora adapters too, so in the network\n",
    "    # any model that have a name in this list will have a lora adapter added to it,\n",
    "    target_modules=['k_proj', 'q_proj', 'v_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7f7268188b40edb4959ef9b22aef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c30b84f76d4c62b051f8ade14fa16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a5196832484fafbbe4bc6b74e977ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12838015e754f72858543d0e4a13e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dca0efd779446eb89139d5a0fa3b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c44a9bf6ea4070a65d4d357c9f2039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "\n",
    "model_checkpoint_path = \"./results/tiny-llama\"\n",
    "\n",
    "# an important note is that the loss function isn't defined here,\n",
    "# it's instead stored as a model parameter for models in hf,\n",
    "# in the case of llama it is cross entropy loss\n",
    "\n",
    "# first define some training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=model_checkpoint_path,\n",
    "    optim='adafactor', #specify what optimizer we wwant to use, in this case a 8bit version of adamw with pagination.\n",
    "    per_device_train_batch_size=8, # define the number of samples per training batch\n",
    "    gradient_accumulation_steps=4, # define how many steps to accumulate gradients,\n",
    "    log_level='debug',\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy='steps', # we'll save a checkpoint every epoch\n",
    "    logging_steps=8,\n",
    "    eval_steps=8,\n",
    "    save_steps=8,\n",
    "    learning_rate=1e-5, # for llm training we want a fairly high learning rate, 1e-4 is a good starting point but it's worth it to play around with this value\n",
    "    fp16=True,\n",
    "    num_train_epochs=4,\n",
    "    max_steps=120,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end = True,\n",
    "    overwrite_output_dir = True,\n",
    "    lr_scheduler_type='linear',# and set our learning rate decay\n",
    ")\n",
    "\n",
    "# now that we have our arguments, we'll use that to create our trainer,\n",
    "# passing in the model, dataset, peft config, tokenizer, ect\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_validation_dataset,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 100,925,440 || all params: 1,200,973,824 || trainable%: 8.4036\n"
     ]
    }
   ],
   "source": [
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6253573894500732, 'eval_model_preparation_time': 0.0023, 'eval_runtime': 71.1943, 'eval_samples_per_second': 14.046, 'eval_steps_per_second': 1.756}\n"
     ]
    }
   ],
   "source": [
    "initial_eval_values = trainer.evaluate()\n",
    "print(initial_eval_values)\n",
    "initial_eval_loss = initial_eval_values['eval_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently training with a batch size of: 8\n",
      "***** Running training *****\n",
      "  Num examples = 15,000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 120\n",
      "  Number of trainable parameters = 100,925,440\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 34:15, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.478400</td>\n",
       "      <td>2.240111</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.927200</td>\n",
       "      <td>1.543350</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.401900</td>\n",
       "      <td>1.233937</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.310200</td>\n",
       "      <td>1.201068</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.233000</td>\n",
       "      <td>1.185550</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.256700</td>\n",
       "      <td>1.175096</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.242000</td>\n",
       "      <td>1.168747</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.219600</td>\n",
       "      <td>1.163846</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.196200</td>\n",
       "      <td>1.160732</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.167400</td>\n",
       "      <td>1.158024</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.256600</td>\n",
       "      <td>1.156096</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.204700</td>\n",
       "      <td>1.155118</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.216800</td>\n",
       "      <td>1.154099</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.195700</td>\n",
       "      <td>1.154259</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.212900</td>\n",
       "      <td>1.154037</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-8\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-8/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-8/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-16\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-16/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-16/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-24\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-24/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-24/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-32\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-32/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-32/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-40\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-40/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-48\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-48/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-48/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-56\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-56/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-64\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-64/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-64/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-72\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-72/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-72/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-80\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-80/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-88\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-88/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-88/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-96\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-96/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-96/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-104\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-104/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-104/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-112\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-112/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-112/special_tokens_map.json\n",
      "/home/hans/miniconda3/envs/moba/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/tiny-llama/checkpoint-120\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./results/tiny-llama/checkpoint-120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/tiny-llama/checkpoint-120/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/tiny-llama/checkpoint-120 (score: 1.1540366411209106).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=1.3679600477218627, metrics={'train_runtime': 2063.7473, 'train_samples_per_second': 1.861, 'train_steps_per_second': 0.058, 'total_flos': 2.678833916411904e+16, 'train_loss': 1.3679600477218627})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/tiny-llama\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in ./models/tiny-llama/tokenizer_config.json\n",
      "Special tokens file saved in ./models/tiny-llama/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./models/tiny-llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4784, 1.9272, 1.4019, 1.3102, 1.233, 1.2567, 1.242, 1.2196, 1.1962, 1.1674, 1.2566, 1.2047, 1.2168, 1.1957, 1.2129]\n",
      "[2.6253573894500732, 2.2401113510131836, 1.5433495044708252, 1.2339366674423218, 1.2010681629180908, 1.1855504512786865, 1.1750962734222412, 1.168746829032898, 1.1638460159301758, 1.1607319116592407, 1.1580238342285156, 1.1560957431793213, 1.155118465423584, 1.154099464416504, 1.1542588472366333, 1.1540366411209106]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss_history = []\n",
    "eval_loss_history = [initial_eval_loss]\n",
    "for step in trainer.state.log_history:\n",
    "  if 'loss' in step:\n",
    "    training_loss_history.append(step['loss'])\n",
    "  elif \"eval_loss\" in step:\n",
    "    eval_loss_history.append(step['eval_loss'])\n",
    "\n",
    "print(training_loss_history)\n",
    "print(eval_loss_history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "time_steps = [i*16 for i in range(1, len(training_loss_history)+1)]\n",
    "plt.plot(time_steps, training_loss_history, label=\"train loss\")\n",
    "plt.plot([0]+time_steps, eval_loss_history, label=\"eval loss\")\n",
    "plt.title(\"Train and Eval Loss During Training\")\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./models/tiny-llama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file chat_template.jinja\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model\n",
      "loading file tokenizer.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 5632,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 22,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 2048,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.model\n",
      "loading file tokenizer.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/hans/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did Beyonce start becoming popular?\n",
      "\n",
      "1. 2003: Beyonce releases her debut album, \"Dangerously in Love.\"\n",
      "2. 2004: Beyonce releases her second album, \"B'Day.\"\n",
      "3. 2005: Beyonce releases her third album, \"I Am... Sasha Fierce.\"\n",
      "4. 2006: Beyonce releases her fourth album, \"Beyonce.\"\n",
      "5. 2007: Beyonce releases her fifth album, \"I Am... World Tour.\"\n",
      "6. 2008: Beyonce releases her sixth album, \"B'Day 2.\"\n",
      "7. 2009: Beyonce releases her seventh album, \"B'Day 3.\"\n",
      "8. 2010: Beyonce releases her eighth album, \"B'Day 4.\"\n",
      "9. 2011: Beyonce releases her ninth album, \"B'Day 5.\"\n",
      "10. 2012: Beyonce releases her tenth album, \"B'Day 6.\"\n",
      "11. 2013: Beyonce\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "trained_adapter_dir = modelpath  # your checkpoint folder clearly stated here\n",
    "\n",
    "# Load base tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Clearly load base model explicitly\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Explicitly load your trained LoRA adapters clearly\n",
    "model = PeftModel.from_pretrained(base_model, trained_adapter_dir)\n",
    "\n",
    "# Set tokenizer explicitly\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Use model explicitly for inference clearly\n",
    "prompt = \"When did Beyonce start becoming popular?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_length=256)\n",
    "\n",
    "response = tokenizer.decode(output.squeeze(), skip_special_tokens=True)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
